\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{geometry}
\setlength{\parindent}{0pt} % Removes paragraph indentation
\setlength{\parskip}{0.5\baselineskip} % Adds half a line of space between paragraphs
\geometry{margin=1in}

\title{A Variational and Geometric Perspective on Learning Dynamics}
\author{Jamie Graham}
\date{2026}
\begin{document}
\maketitle

We present an integrated variational--geometric perspective on learning dynamics and identify structural principles shared across optimization, inference, and generative modeling.

\section{Central Questions}

\begin{itemize}
\item What structural principles govern the dynamics of learning, and how do variational and geometric ideas clarify their relationships?
\item In what precise sense can learning dynamics be understood as variational flows of energy functionals under chosen geometric and stochastic structures?
\item What is the minimal geometric and variational structure required to describe modern learning algorithms?
\item Can deterministic optimization, stochastic gradient methods, variational inference, and diffusion be described within a common variational--geometric framework, and what structural elements differentiate them?
\end{itemize}

\section{Core Sections}
\begin{itemize}
\item Variational Mechanics
\item Gradient Flows as Dissipative Variational Systems
\item Stochastic Extensions and Thermodynamic Structure
\item Distribution-Space Dynamics
\item Connections to Optimization, VI, Diffusion
\end{itemize}

\section{Variational Mechanics and Trajectory Optimization}

\subsection{Dynamical Systems}

A dynamical system is a mathematical framework used to describe how something changes over time. It provides a rule that determines how the state of a system evolves, given its current condition. The state represents the complete information needed to describe the system at a particular moment, such as the position of a particle, the configuration of a mechanical system, or the activity of a network. Once the system's initial state is specified, the dynamical system determines how that state develops into the future (and sometimes the past).

You can think of a dynamical system as consisting of two main ingredients: a space of possible states and a rule that describes how states change with time. As time progresses, the system follows a trajectory through this state space, representing its evolution.

In classical mechanics, it is helpful to distinguish \textbf{configuration} from \textbf{state}. A configuration is a point $q \in Q$ recording ``where the system is,'' while the \textbf{mechanical state} is typically $(q,\dot q) \in TQ$. Velocities complete the state because mechanical laws are usually \textbf{second-order} in time: specifying $q(t_0)$ alone does not determine the future, but specifying $(q(t_0),\dot q(t_0))$ does (given the forces/constraints).

Formally, let $M$ be a state space (often modeled as a smooth manifold). A continuous-time dynamical system is defined by a rule that assigns a trajectory to each initial state. This is typically specified by a differential equation of the form
\begin{equation}
\frac{dx}{dt} = F(x, t)
\end{equation}
where $x(t) \in M$ represents the state of the system at time $t$, and $F$ is a function that determines how the state changes over time.

Equivalently, a dynamical system can be described by a flow
\begin{equation}
\phi_t : M \rightarrow M
\end{equation}
such that $\phi_t(x_0)$ gives the state of the system at time $t$ starting from the initial state $x_0$, and satisfies
\begin{equation}
\phi_0(x) = x, \quad \phi_{t+s}(x) = \phi_t(\phi_s(x)).
\end{equation}

Under standard regularity assumptions (e.g.\ the vector field $F$ is locally Lipschitz in $x$), these viewpoints are equivalent: $F$ generates the flow $\phi_t$ via solutions of the ODE, and $\phi_t$ recovers $F$ by differentiation at $t=0$.

\subsection{Configuration Space $Q$}

In mechanics, a \textbf{Configuration Space} $Q$ is a mathematical space where each point represents one complete way a system can be arranged or positioned. Instead of tracking objects directly in physical space, we describe the system using the smallest set of coordinates needed to uniquely specify its state.

Each set of coordinate values corresponds to a single point in configuration space, and as the system changes over time it traces a path through this space. The number of dimensions in configuration space equals the number of independent coordinates needed to describe the system. Thinking this way allows complex motion to be understood as movement through a geometric space of possibilities.

For example, a single particle moving in ordinary space can be fully described by three coordinates
\begin{equation}
(q_1,q_2,q_3)
\end{equation}
so its configuration space is simply three-dimensional space $\mathbb{R}^3$, where each point represents one possible position of the particle.

\subsection{Mechanical State Space $TQ$}

For mechanical systems, the natural state space is not $Q$ itself but instead a space called the \textbf{tangent bundle} $TQ$. Intuitively, $TQ$ is the space of all pairs $(q,v)$ where $q\in Q$ and $v \in T_qQ$ is a \textbf{tangent vector} at $q$, interpreted as a velocity.

This is why \textbf{Lagrangians live on $TQ$}: at each time $t$, the velocity $\dot q(t)$ is literally a tangent vector $\dot q(t)\in T_{q(t)}Q$, so $L$ must accept both $q$ and $\dot q$ as inputs.

\subsection{Dynamical Trajectories $q(t)$}

A dynamical system evolves over time by moving through its configuration space. The function $q(t)$ describes this evolution by specifying the system's configuration at each moment in time. In other words, for every time $t$, the value of $q(t)$ tells you exactly where the system is within the space of all possible configurations.

As time varies, $q(t)$ traces out a continuous curve through configuration space. This curve is called the system's \textbf{trajectory}, and it represents the full history of how the system moves from one configuration to another.

The quantity $\dot{q}(t)$ describes how the system moves along this trajectory. It represents the \textbf{velocity through configuration space}, indicating both how quickly the configuration is changing and in what direction it is changing at time $t$. While $q(t)$ specifies the system's position in configuration space, $\dot{q}(t)$ describes how that position is evolving.

Together, $q(t)$ and $\dot{q}(t)$ describe both where the system is and how it is moving. We typically assume trajectories are at least continuously differentiable ($C^1$) so that $\dot q(t)$ exists.

Formally, let $Q$ denote the configuration space of a system (typically modeled as a smooth manifold). A trajectory of the system is defined as a smooth time-parameterized curve
\begin{equation}
q : I \rightarrow Q
\end{equation}
where $I \subseteq \mathbb{R}$ is a time interval and $q(t)$ specifies the system's configuration at time $t$.

The velocity of the system is defined as the time derivative of this curve. At each time $t$, the velocity is an element of the tangent space of $Q$ at the point $q(t)$:
\begin{equation}
\dot{q}(t) = \frac{dq}{dt}(t) \in T_{q(t)}Q
\end{equation}
where $T_{q(t)}Q$ denotes the tangent space to the configuration space at $q(t)$.

Equivalently, the pair
\begin{equation}
(q(t), \dot{q}(t))
\end{equation}
defines a curve in the tangent bundle $TQ$, which is the space containing all configurations together with their associated velocities.

\subsection{Functionals}

A functional is a mathematical rule that takes an entire function as its input and produces a single number as its output. Instead of operating on individual numbers or vectors, a functional evaluates properties of whole curves, shapes, or fields. You can think of it as a way of assigning a numerical value to an entire path or configuration, often measuring quantities like total energy, length, or accumulated cost. Functionals are especially useful when studying systems where the object of interest is not a single point, but a continuous trajectory or distribution. In many areas of physics and mathematics, the behavior of a system can be determined by finding the function that makes a particular functional as small or large as possible.

For example, if $y(x)$ is a curve between two points, the expression
\begin{equation}
J[y] = \int_a^b y(x)^2  dx
\end{equation}
is a functional because it takes the entire function $y(x)$ as input and outputs a single number representing the total accumulated squared value of the curve.

Formally, a functional is a mapping
\begin{equation}
J : \mathcal{F} \to \mathbb{R}
\end{equation}
where $\mathcal{F}$ is a space of functions (such as continuous or differentiable functions) and $J$ assigns a real number to each function in that space.

\subsection{Lagrangian Formalism}

A Lagrangian $L(q, \dot{q}, t)$ is a mathematical function that summarizes how a physical system moves by describing the balance between motion and stored energy. It is typically written as a function of a system's coordinates $q$, their rates of change $\dot{q}$, and time $t$, and it encodes the rules governing the system's dynamics. Instead of directly computing forces like in Newtonian mechanics, the Lagrangian allows us to determine motion by identifying the path a system takes between two configurations. This is done by constructing a quantity called the action and finding the path that makes this quantity \textbf{stationary} (often minimal in physical systems).

Lagrangians can be thought of as a \textbf{cost density} or a \textbf{scoring rule} that tells us how ``favorable'' or ``natural'' a system's motion is at each moment in time. At its core often in classical mechanics, it measures a balance between two competing tendencies: kinetic energy $T$, which reflects how strongly a system is moving or spreading its motion, and potential energy $V$, which reflects how strongly the system is being pulled toward or held by its environment. The difference $T - V$ can be thought of as measuring how freely the system is able to move relative to how constrained or trapped it is. If kinetic energy is large compared to potential energy, the system is moving freely; if potential energy dominates, the system is strongly restricted by forces or stored energy. You can imagine it like a traveler balancing momentum with terrain: $T$ rewards motion and exploration, while $V$ represents hills, valleys, or constraints that shape which routes are natural or costly. The system's actual motion is determined by combining this balance over time into a total quantity called the action and selecting the path that makes this total score \textbf{stationary} (often minimal in physical systems). This viewpoint matters because it reframes ``solving the equations of motion'' as an optimization-style problem over trajectories. That is to say, variational mechanics reformulates dynamics as optimization over function spaces.

We will use the following \textbf{running example} throughout this section.

For a single particle of mass $m$ moving in one dimension with position $q(t)$ in a potential energy field $V(q)$, the Lagrangian is
\begin{equation}
L(q, \dot{q}, t) = T - V = \frac{1}{2} m \dot{q}^2 - V(q)
\end{equation}
where $\dot{q}$ is the particle's velocity, $T$ is kinetic energy, and $V$ is potential energy. Additionally, while classical mechanical systems often use $T-V$, modern variational formulations allow far more general Lagrangians.

Formally, a Lagrangian is a function
\begin{equation}
L : TQ \times \mathbb{R} \rightarrow \mathbb{R}
\end{equation}
where $Q$ is the configuration space of the system, $TQ$ is its tangent bundle (the space of coordinates $q$ and velocities $\dot{q}$), and $L(q, \dot{q}, t)$ assigns a real number to each configuration, velocity, and time.

\subsection{Action Functional}

We now introduce the central object linking \textbf{dynamics} and \textbf{optimization}. The \textbf{action functional} assigns a single number to an entire trajectory. Instead of evaluating the Lagrangian at one instant, we integrate $L(q,\dot q,t)$ over time between two fixed moments $t_0$ and $t_1$. That integral measures the total ``cost'' or ``score'' accumulated along the path. Physical trajectories are those that make this total score \textbf{stationary}---small variations of the path do not change the value of the action to first order. So the action functional turns the question ``what path does the system follow?'' into an optimization problem over curves: nature (or an algorithm) chooses the path that makes $S$ stationary over all curves in a space of infinite dimensional functions connecting the same endpoints.
\begin{equation}
S[q(\cdot)] = \int_{t_0}^{t_1} L(q(t), \dot{q}(t), t)\, dt
\end{equation}
Where:
\begin{itemize}
\item $q(t)$ is a trajectory in configuration space $Q$
\item $\dot{q}(t)$ is velocity (a tangent vector in $T_{q(t)}Q$)
\item $L$ is the Lagrangian
\end{itemize}

Typically, one varies over trajectories satisfying boundary conditions $q(t_0)=q_0$ and $q(t_1)=q_1$, and seeks paths that make $S$ \textbf{stationary} (often minimal in physical systems). In our running example, substituting $L(q,\dot q,t)=\tfrac12 m\dot q^2 - V(q)$ makes $S[q(\cdot)]$ an explicit ``score'' assigned to entire paths.

\subsection{Toward the Euler--Lagrange Equation}

Knowing that physical trajectories are those that make the action stationary is not yet enough to \emph{compute} them. We need a \textbf{local} condition---a differential equation---that a curve must satisfy at each time if it is to extremize $S$. That condition is the \textbf{Euler--Lagrange equation}.
\begin{equation}
\frac{\partial L}{\partial x} -
\frac{d}{dt} \frac{\partial L}{\partial \dot{x}}  = 0
\end{equation}

We will motivate that this condition emerges naturally from the stationarity condition on the action functional. Consider this as an analogue of setting the derivative to zero in ordinary calculus: instead of ``derivative of a function equals zero at a critical point,'' we get ``a certain combination of derivatives of $L$ evaluated along the curve equals zero at each time.''

Our derivation proceeds by \textbf{variation}. We take a candidate trajectory $q(t)$ and perform a first-order perturbation of it slightly to $q(t) + \epsilon\,\eta(t)$, where $\eta(t)$ is an arbitrary smooth function that vanishes at the endpoints, giving the boundary condition:
\begin{equation}
\eta(t_0) = \eta(t_1) = 0
\end{equation}
Thus we only consider curves that still connect the same two configurations $q_0$ and $q_1$.

We then ask: for $S[q(t)]$ to be stationary at $q(t)$, the first-order change in $S$ with respect to $\epsilon$ must vanish for \emph{every} such perturbation $\eta$, that is:
\begin{equation}
\delta S = \frac{d}{d \epsilon}S[q(t) + \epsilon\eta(t)] \bigg|_{\epsilon=0} = 0
\end{equation}

Let us also insert our first order perturbation of the trajectory $q(t)$ into the action functional.
\begin{equation}
S[q(t) + \epsilon\eta(t)] = \int_{t_0}^{t_1} L(q(t) + \epsilon\eta(t), \dot{q}(t) + \epsilon\dot{\eta}(t), t)\, dt
\end{equation}

Altogether, this gives us
\begin{equation}
\delta S = \int \left(\frac{\partial L}{\partial q} \eta
+ \frac{\partial L}{\partial \dot{q}} \dot{\eta}\right) dt = 0
\end{equation}

This shows that the variation of the action functional is seperable into a term that encodes sensitivity to position as well as senstitivity to velocity, hinting that motion depends on both.

We now perform a trick on the second term, using integration by parts.
\begin{equation}
\int \left(\frac{\partial L}{\partial \dot{q}} \dot{\eta}\right) dt
\end{equation}
Integrating by parts:
\begin{equation}
= \left[ \frac{\partial L}{\partial \dot{q}} \eta(t) \right]_{t_0}^{t_1}
- \int \frac{d}{dt} \left(\frac{\partial L}{\partial \dot{q}}\right) \eta(t)  dt
\end{equation}

But notice that the first term vanishes due to the aforementioned boundary conditions. $\eta(t_0) = \eta(t_1) = 0$

So we obtain:
\begin{equation}
\delta S =
\int
\left(
\frac{\partial L}{\partial q} -
\frac{d}{dt} \frac{\partial L}{\partial \dot{q}}
\right)
\eta(t)
dt = 0
\end{equation}

Note now that the variation of $S$ collapses into a single term multiplied by an arbitary smooth function $\eta(t)$, yet in order for the action to be stationary for all admissable variations, the integral must be equal to zero. Since $\eta(t)$ is arbitary, the only way this is possible is if the condition
\begin{equation}
\frac{\partial L}{\partial q} -
\frac{d}{dt} \frac{\partial L}{\partial \dot{q}}  = 0
\end{equation}
which is the Euler-Lagrange equation, so we are done.
\begin{equation}
\square
\end{equation}

Intuitively, we see that the Euler-Lagrange equation emerges as a local constraint on the Lagrangian, following from extremizing the action functional $S$.

\subsection{On The Implications of Stationary Action}

What does stationary action really imply?
\begin{equation}
\delta S = 0
\end{equation}
This means that the physical trajectory $q(t)$ that emerges in a system is a stationary point in function space. This is not necessarily a minimum, it could be a maximum or saddle point, but it is a stationary point.

\subsection{An Example: Recovering Newton's Second Law from Stationary Action}

A single particle of mass $m$ in one dimension with position $x(t)$ in a potential $V(x)$ has Lagrangian
\begin{equation}
L = \frac{1}{2} m \dot{x}^2 - V(x).
\end{equation}

Applying the Euler--Lagrange equation
\begin{equation}
\frac{\partial L}{\partial x} - \frac{d}{dt}\frac{\partial L}{\partial \dot{x}} = 0
\end{equation}

In one dimension, we note that the partial derivative of the Lagrangian with respect to $x$ is actually equal to the negative gradient of the potential.
\begin{equation}
\frac{\partial L}{\partial x} = -\frac{\partial V}{\partial x} = -\nabla V
\end{equation}

Note that taking the derivative of the lagrangian with resepect to velocity gives
\begin{equation}
\frac{\partial L}{\partial \dot{x}} = m\dot{x}
\end{equation}

Taking a time derivative gives
\begin{equation}
\frac{d}{dt}\frac{\partial L}{\partial \dot{x}} = m\ddot{x}
\end{equation}

Substituting Euler-Lagrange, we get
\begin{equation}
m\ddot{x} = -\nabla V = F
\end{equation}

Which is Newton's second law. Note that Newton's second law thus emerges from the Euler-Lagrange equation, which emerges from stationary action.

Local dynamics (the ODE at each instant) emerges from global optimization (extremizing $S$ over entire trajectories). This is a central insight we can apply to modern settings, where trajectory selection by a variational principle appears in learning and diffusion.


\section{Gradient Flows as Dissipative Variational Systems}

\subsection{From Stationary Action to Energy Dissipation}

In classical variational mechanics, trajectories arise from the stationarity of an action functional. Under suitable regularity assumptions, this yields Eulerâ€“Lagrange equations whose associated dynamics are typically conservative. In particular, for time-independent Lagrangians, the Hamiltonian energy
\begin{equation}
H(q,\dot q)
\end{equation}
is preserved along trajectories:
\begin{equation}
\frac{d}{dt} H(q(t),\dot q(t)) = 0.
\end{equation}
The variational principle therefore selects trajectories consistent with energy conservation rather than energy decay.

Learning dynamics, by contrast, are intrinsically dissipative. Let
\begin{equation}
\mathcal{E} : \Theta \to \mathbb{R}
\end{equation}
denote a loss or objective functional defined on a parameter space $\Theta$. A fundamental property of most training procedures is that along the trajectory $\theta(t)$, the objective decreases:
\begin{equation}
\frac{d}{dt} \mathcal{E}(\theta(t)) \le 0.
\end{equation}
Rather than preserving an energy functional, learning algorithms are designed to drive the system toward lower-energy configurations.

This structural distinction suggests that stationary action is not the appropriate variational framework for learning. Instead, learning dynamics are more naturally described as gradient flows of energy functionals, in which dissipation is fundamental rather than accidental.

In the context of supervised learning, the energy functional $\mathcal{E}$ may represent empirical risk,
\begin{equation}
\mathcal{E}(\theta) = \frac{1}{n} \sum_{i=1}^n \ell(f_\theta(x_i), y_i),
\end{equation}

where $f_\theta$ is a parameterized model and $\ell$ a loss function. More generally, $\mathcal{E}$ may denote any differentiable objective functional whose minimization defines the learning problem.


\subsection{Gradient Flow in Euclidean Parameter Space}

A gradient flow is a continuous-time dynamical system that evolves according to the direction of steepest descent of an energy functional. 

The gradient flow of an energy functional is defined by the following differential equation:

\begin{equation}
\dot{\theta}(t) = -\nabla \mathcal{E}(\theta(t)).
\end{equation}


Taking the time derivative of the energy functional, we get:
\begin{equation}
\frac{d}{dt} \mathcal{E}(\theta(t)) = \langle \nabla \mathcal{E}(\theta(t)), \dot{\theta}(t) \rangle
\end{equation}

Substituting the gradient flow equation into the time derivative of the energy functional, we get:
\begin{equation}
\frac{d}{dt} \mathcal{E}(\theta(t)) = -\langle \nabla \mathcal{E}(\theta(t)), \nabla \mathcal{E}(\theta(t)) \rangle = - |\nabla \mathcal{E}(\theta(t))|^2 \le 0
\end{equation}

Thus the energy decreases monotonically along trajectories of the flow. In contrast to conservative Euler--Lagrange dynamics, where stationarity of an action yields energy preservation, gradient flow dynamics are intrinsically dissipative: the energy functional itself drives motion toward lower-energy configurations.

Importantly, the definition of the gradient depends on the underlying metric structure on $\Theta$. The Euclidean inner product induces the standard gradient operator; alternative choices of geometry give rise to distinct gradient flows.

\subsection{Minimizing Movements: A Dissipative Variational Principle}

Although gradient flow is defined as a differential equation, it admits an equivalent variational characterization. This formulation restores variational structure in a manner fundamentally distinct from stationary action.

Let $\eta > 0$ be a time-step parameter. Given a current state $\theta_k \in \Theta$, define the next state by the minimization problem
\begin{equation}
\theta_{k+1}
=
\arg\min_{\theta \in \Theta}
\left\{
\mathcal{E}(\theta)
+
\frac{1}{2\eta} \|\theta - \theta_k\|^2
\right\}.
\end{equation}

This scheme selects the subsequent state by balancing two competing effects:
\begin{itemize}
\item reduction of the energy $\mathcal{E}$,
\item proximity to the previous state $\theta_k$.
\end{itemize}

Unlike stationary action, which selects entire trajectories through a global extremization principle, the minimizing movement scheme determines evolution incrementally through a sequence of local variational problems over states.

As $\eta \to 0$, the piecewise-linear interpolation of the discrete iterates converges, under suitable regularity assumptions, to the solution of the gradient flow equation
\begin{equation}
\dot{\theta}(t) = - \nabla \mathcal{E}(\theta(t)).
\end{equation}

In this sense, gradient flow may be understood as the continuous-time limit of a time-discrete variational principle. Dissipation therefore arises not from stationary action over trajectories, but from successive minimization of energy penalized by a metric cost of motion.

Stationary action extremizes a functional over curves in configuration space, whereas minimizing movements extremize a functional over successive states in metric space. The former produces conservative dynamics; the latter generates dissipative evolution.

\subsection{Gradient Flow on a Riemannian Manifold}

The notion of gradient depends fundamentally on the underlying metric structure of the state space. To make this dependence explicit, let $(M,g)$ be a Riemannian manifold and let $\mathcal{E} : M \to \mathbb{R}$ be a smooth energy functional.

At each point $\theta \in M$, the differential $d\mathcal{E}_\theta$ defines a covector in the cotangent space $T_\theta^* M$. The Riemannian metric $g$ induces an identification between tangent and cotangent spaces, allowing one to define the Riemannian gradient $\nabla_g \mathcal{E}$ implicitly by
\begin{equation}
g_\theta(\nabla_g \mathcal{E}, v) = d\mathcal{E}_\theta(v)
\quad \text{for all } v \in T_\theta M.
\end{equation}

The gradient flow of $\mathcal{E}$ with respect to the metric $g$ is then defined by
\begin{equation}
\dot{\theta}(t) = - \nabla_g \mathcal{E}(\theta(t)).
\end{equation}

Along any sufficiently smooth solution of this equation, the energy evolves according to
\begin{equation}
\frac{d}{dt} \mathcal{E}(\theta(t))
= d\mathcal{E}_\theta(\dot{\theta})
= - g_\theta(\nabla_g \mathcal{E}, \nabla_g \mathcal{E})
= - \|\nabla_g \mathcal{E}\|_g^2 \le 0.
\end{equation}

Thus the dissipative character of the dynamics is preserved under arbitrary choices of Riemannian geometry: the energy decreases at a rate determined by the squared norm of its gradient with respect to the metric $g$.

\subsection{Conservative and Dissipative Variational Structures}

The preceding sections exhibit two distinct variational paradigms. Classical mechanics arises from stationarity of an action functional over trajectories and yields conservative dynamics. Learning dynamics, by contrast, arise from gradient flow of an energy functional and yield dissipative evolution.

The structural differences may be summarized as follows:

\begin{center}
\begin{tabular}{l|l}
\textbf{Conservative Dynamics} & \textbf{Dissipative Dynamics} \\
\hline
Action functional over trajectories & Energy functional over states \\
Euler--Lagrange / Hamiltonian equations & Gradient flow equations \\
Second-order in time & First-order in time \\
Energy preserved ($\frac{dH}{dt}=0$) & Energy decreases ($\frac{d\mathcal{E}}{dt} \le 0$) \\
Symplectic structure & Metric structure \\
\end{tabular}
\end{center}

Conservative systems preserve geometric structure and exhibit reversible evolution. Dissipative systems contract energy and generically exhibit irreversible behavior. While both arise from variational principles, the nature of the extremization differs fundamentally: stationary action selects entire trajectories, whereas gradient flow emerges from successive minimization of energy relative to a metric cost of motion.


\end{document}


